{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "QuestionNumber = 5  # question per page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to organize answers\n",
    "\n",
    "def arrange_answers(answers):    # organize answers in one instance\n",
    "    arranged_answers =[[] for _ in range(QuestionNumber)]\n",
    "    for name in answers.keys():\n",
    "        answer = answers[name].strip().lower()    # remove sapce & convert to lower\n",
    "        for i in range(QuestionNumber):\n",
    "            if \"answer\"+str(i+1)+\"-\" in name:     # belong to question i\n",
    "                arranged_answers[i].append(answer)\n",
    "    return [sorted(set(t), key=t.index) for t in  arranged_answers]  # remove repeated answer # keep the answer order\n",
    "\n",
    "\n",
    "def answer_frequency(Answers):          # count the frequency of each answer\n",
    "    ritem = dict()\n",
    "    for ans in Answers:\n",
    "        if ans in ritem: ritem[ans] += 1\n",
    "        else: ritem[ans] = 1\n",
    "    return ritem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to calculate metrics\n",
    "\n",
    "def human_metric(anss,StandAnswer=None,RemoveZero=False):\n",
    "    '''\n",
    "    Calculate metrics for answers of one question\n",
    "    Input:\n",
    "    anss: All answers for one question\n",
    "    StandAnswer: Standard answer; \n",
    "        If 'None', only take the most frequent word as the \"mode\"\n",
    "    RemoveZero: Using RemoveZero method or not\n",
    "    '''\n",
    "    if len(anss) == 1:          # only one answer for this question\n",
    "        if len(anss[0]) != 0:   # this one answer is not empty\n",
    "            return [[1] for _ in range(8)]\n",
    "        else:                   # this one answer is empty\n",
    "            return [[0] for _ in range(8)]\n",
    "    # the first,the best,the average of first 3,the average of all\n",
    "    Met1s = [[] for _ in range(4)]\n",
    "    Met2s = [[] for _ in range(4)]\n",
    "    ResWorkerNumber = len(anss)-1\n",
    "    for ind in range(len(anss)):\n",
    "        ans = anss[ind]\n",
    "        if len(anss[ind]) == 0:\n",
    "            for mi in range(4): Met1s[mi].append(0)\n",
    "            for mi in range(4): Met2s[mi].append(0)\n",
    "        else:                   # answer not empty\n",
    "            Otherans = [anss[i] for i in range(len(anss)) if i != ind]\n",
    "            OtherAns = [ite for eachans in Otherans for ite in eachans]\n",
    "            AnsCountDic = answer_frequency(OtherAns)\n",
    "            # find mode\n",
    "            modes = [sorted(AnsCountDic.items(),key=lambda item:item[1])[-1][0]]\n",
    "            ModeFreq = AnsCountDic[modes[0]]\n",
    "            if StandAnswer is not None:  # ground truth is also a mode\n",
    "                modes.append(StandAnswer)\n",
    "            metric1s = [AnsCountDic[ite]/ModeFreq if ite in AnsCountDic \n",
    "                        else 0 for ite in ans]\n",
    "            metric2s = [1 if ite in modes else \n",
    "                        AnsCountDic[ite]/ResWorkerNumber if ite in AnsCountDic \n",
    "                        else 0 for ite in ans]\n",
    "            # the first,the best,the average of first 3,the average of all\n",
    "            Met1s[0].append(metric1s[0])\n",
    "            Met1s[1].append(max(metric1s))\n",
    "            Met1s[2].append(np.average(metric1s[:3]) if len(metric1s) >=3 else np.average(metric1s))\n",
    "            Met1s[3].append(np.average(metric1s))\n",
    "            Met2s[0].append(metric2s[0])\n",
    "            Met2s[1].append(max(metric2s))\n",
    "            Met2s[2].append(np.average(metric2s[:3]) if len(metric2s) >=3 else np.average(metric2s))\n",
    "            Met2s[3].append(np.average(metric2s))\n",
    "    if RemoveZero:          # remove the zero score answers in the first round\n",
    "        remain = [Met1s[1][ite] != 0 for ite in range(len(Met1s[1]))]  # mark whether to remain the answers\n",
    "        Met1s = [[] for _ in range(4)]\n",
    "        Met2s = [[] for _ in range(4)]\n",
    "        for ind in range(len(anss)):\n",
    "            ans = anss[ind]\n",
    "            if len(ans)==0 or remain[ind]==0:\n",
    "                for mi in range(4): Met1s[mi].append(0)\n",
    "                for mi in range(4): Met2s[mi].append(0)\n",
    "            else:                   # answer not empty\n",
    "                Otherans = [anss[i] for i in range(len(anss)) if (i!=ind and remain[i]!=0)]\n",
    "                OtherAns = [ite for eachans in Otherans for ite in eachans]\n",
    "                resworkernumber = len(Otherans)\n",
    "                if resworkernumber != 0:\n",
    "                    AnsCountDic = answer_frequency(OtherAns)\n",
    "                    # find mode\n",
    "                    modes = [sorted(AnsCountDic.items(),key=lambda item:item[1])[-1][0]]\n",
    "                    ModeFreq = AnsCountDic[modes[0]]\n",
    "                    if StandAnswer is not None:  # ground truth is also a mode\n",
    "                        modes.append(StandAnswer)\n",
    "                    metric1s = [AnsCountDic[ite]/ModeFreq if ite in AnsCountDic \n",
    "                                else 0 for ite in ans]\n",
    "                    metric2s = [1 if ite in modes else \n",
    "                                AnsCountDic[ite]/resworkernumber if ite in AnsCountDic \n",
    "                                else 0 for ite in ans]\n",
    "                    Met1s[0].append(metric1s[0])\n",
    "                    Met1s[1].append(max(metric1s))\n",
    "                    Met1s[2].append(np.average(metric1s[:3]) if len(metric1s) >=3 else np.average(metric1s))\n",
    "                    Met1s[3].append(np.average(metric1s))\n",
    "                    Met2s[0].append(metric2s[0])\n",
    "                    Met2s[1].append(max(metric2s))\n",
    "                    Met2s[2].append(np.average(metric2s[:3]) if len(metric2s) >=3 else np.average(metric2s))\n",
    "                    Met2s[3].append(np.average(metric2s))\n",
    "                else:     # No other answers left \n",
    "                    for mi in range(4): Met1s[mi].append(1)\n",
    "                    for mi in range(4): Met2s[mi].append(1)\n",
    "    return np.concatenate((np.array(Met1s).T,np.array(Met2s).T),axis=1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CollectAnswerInformation(original_val,original_test,original_result,remove_zero=False):\n",
    "    \n",
    "    ValMatrics = []   # collect Validation answers for all HITs, all answers\n",
    "    TestMatrics = []  # collect Test answers for all HITs, all answers\n",
    "\n",
    "    # scan Batch_results & cluster answers & calculate score matrix\n",
    "    last_hit_id = None\n",
    "\n",
    "    for ri, (index, row) in enumerate(original_result.iterrows()):\n",
    "        current_hit_id = row[\"HITId\"]\n",
    "        if (last_hit_id is not None) and (current_hit_id == last_hit_id):                              # same HIT\n",
    "            line_answer = arrange_answers(eval(row[\"Answer.taskAnswers\"])[0])\n",
    "            for i in range(QuestionNumber):\n",
    "                answers[i].append(line_answer[i])\n",
    "        if (last_hit_id is not None) and (current_hit_id!=last_hit_id or ri==len(original_result)-1):  # a new HIT or the Last row\n",
    "            # generate precision, recall, score, size matrix for this HIT\n",
    "            for qid in range(QuestionNumber):\n",
    "                humat = human_metric(answers[qid],std_answers[qid],RemoveZero=remove_zero)\n",
    "                if dataset_flag[qid] == \"val\":\n",
    "                    ValMatrics.append(humat)\n",
    "                elif dataset_flag[qid] == \"test\":\n",
    "                    TestMatrics.append(humat)\n",
    "        if  last_hit_id == None or current_hit_id!=last_hit_id:              # collect information & answers for the new HIT\n",
    "            last_hit_id = current_hit_id\n",
    "            video_ids = [row[\"Input.video\"+str(wid)+\"_id\"] for wid in range(1,QuestionNumber+1)]\n",
    "            video_questions = [row[\"Input.question\"+str(wid)] for wid in range(1,QuestionNumber+1)]\n",
    "            postags = [row[\"Input.pos_tag\"+str(wid)] for wid in range(1,QuestionNumber+1)]\n",
    "            std_answers = []  # standard answers\n",
    "            dataset_flag = []  # mark the source dataset\n",
    "            for wid in range(QuestionNumber):\n",
    "                try:  # search validation dataset\n",
    "                    std_ans = original_val[(original_val.video_id==video_ids[wid]) &\n",
    "                                           (original_val.question==video_questions[wid])][\"answer\"].iloc[0]\n",
    "                    dflg = \"val\"\n",
    "                except:  # search test dataset\n",
    "                    std_ans = original_test[(original_test.video_id==video_ids[wid]) &\n",
    "                                           (original_test.question==video_questions[wid])][\"answer\"].iloc[0]\n",
    "                    dflg = \"test\"\n",
    "                std_answers.append(std_ans)\n",
    "                dataset_flag.append(dflg)\n",
    "            answers = [[] for _ in range(QuestionNumber)]                    # answers for one HIT\n",
    "            line_answer = arrange_answers(eval(row[\"Answer.taskAnswers\"])[0])\n",
    "            for i in range(QuestionNumber):\n",
    "                answers[i].append(line_answer[i])\n",
    "    return ValMatrics, TestMatrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch1_result = pd.read_csv(\"Batch_4058534_batch_results.csv\")\n",
    "batch2_result = pd.read_csv(\"Batch_4090592_batch_results.csv\")\n",
    "original_result = pd.concat([batch1_result,batch2_result],axis=0)\n",
    "val = pd.read_csv(\"Validation.csv\")\n",
    "test = pd.read_csv(\"Test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ValMatrics,TestMatrics = CollectAnswerInformation(val,test,original_result,remove_zero=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the first,the best,the average of first 3,the average of all\n",
    "ValMatrics=np.array([ite2 for ite1 in ValMatrics for ite2 in ite1])\n",
    "TestMatrics=np.array([ite2 for ite1 in TestMatrics for ite2 in ite1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.55305544, 0.67921498, 0.4360409 , 0.41466375, 0.52282873,\n",
       "       0.64403387, 0.40480417, 0.38397277])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(ValMatrics,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.55527347, 0.69231947, 0.43867244, 0.41911915, 0.54141623,\n",
       "       0.67520415, 0.42384358, 0.40431809])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(TestMatrics,axis=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
