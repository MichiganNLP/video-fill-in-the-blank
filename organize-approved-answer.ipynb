{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "QuestionNumber = 5  # question per page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arrange_answers(answers):    # organize answers in one instance\n",
    "    arranged_answers =[[] for _ in range(QuestionNumber)]\n",
    "    for name in answers.keys():\n",
    "        answer = answers[name].strip().lower()    # remove sapce & convert to lower\n",
    "        for i in range(QuestionNumber):\n",
    "            if \"answer\"+str(i+1)+\"-\" in name:     # belong to question i\n",
    "                arranged_answers[i].append(answer)\n",
    "    return [list(set(t)) for t in  arranged_answers]  # remove repeated answer\n",
    "\n",
    "\n",
    "def answer_frequency(Answers, Total_number):          # count the frequency of each answer\n",
    "    ritem = dict()\n",
    "    for ans in Answers:\n",
    "        if ans in ritem: ritem[ans][0] += 1\n",
    "        else: ritem[ans] = [1,Total_number]\n",
    "    return ritem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect information & answers & review result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_result = pd.read_csv(\"Batch_4058534_batch_results.csv\")\n",
    "original_dataset = pd.read_csv(\"val1.csv\") # look for standard answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## HIT-information dictionary\n",
    "hit_info = dict()\n",
    "\n",
    "# scan batch result\n",
    "last_hit_id = None\n",
    "for ri, (index, row) in enumerate(original_result.iterrows()):\n",
    "    current_hit_id = row[\"HITId\"]\n",
    "    if (last_hit_id is not None) and (current_hit_id == last_hit_id):                              # same HIT\n",
    "        line_answer = arrange_answers(eval(row[\"Answer.taskAnswers\"])[0])\n",
    "        for i in range(QuestionNumber):\n",
    "            answers[i].append(line_answer[i])\n",
    "    if (last_hit_id is not None) and (current_hit_id!=last_hit_id or ri==len(original_result)-1):  # a new HIT or the Last row\n",
    "        hit_info[last_hit_id] = {\"VideoIds\":video_ids,\"Questions\":video_questions,\"StartTimes\":start_times,\n",
    "                                 \"EndTimes\":end_times,\"Postags\":postags,\"StdAnswers\":std_answers,\"Answers\":[]}\n",
    "        for fwid in range(QuestionNumber):\n",
    "            qanswers = []                                      # answers for one question\n",
    "            for canid in range(len(answers[fwid])):\n",
    "                qanswers.append(answers[fwid][canid])\n",
    "            hit_info[last_hit_id][\"Answers\"].append(qanswers)\n",
    "    if  last_hit_id == None or current_hit_id!=last_hit_id:    # collect information & answers for the new HIT\n",
    "        last_hit_id = current_hit_id\n",
    "        video_ids = [row[\"Input.video\"+str(wid)+\"_id\"] for wid in range(1,QuestionNumber+1)]\n",
    "        video_questions = [row[\"Input.question\"+str(wid)] for wid in range(1,QuestionNumber+1)]\n",
    "        postags = [row[\"Input.pos_tag\"+str(wid)] for wid in range(1,QuestionNumber+1)]\n",
    "        start_times = [row[\"Input.video\"+str(wid)+\"_start_time\"] for wid in range(1,QuestionNumber+1)]\n",
    "        end_times = [row[\"Input.video\"+str(wid)+\"_end_time\"] for wid in range(1,QuestionNumber+1)]\n",
    "        std_answers = [original_dataset[(original_dataset.video_id==video_ids[wid]) \n",
    "                                        & (original_dataset.question==video_questions[wid])\n",
    "                                       ][\"answer\"].iloc[0] for wid in range(QuestionNumber)]\n",
    "        answers = [[] for _ in range(QuestionNumber)]          # answers for one HIT\n",
    "        line_answer = arrange_answers(eval(row[\"Answer.taskAnswers\"])[0])\n",
    "        for i in range(QuestionNumber):\n",
    "            answers[i].append(line_answer[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIT-review result dictionary\n",
    "hit_review = dict()\n",
    "\n",
    "with open(\"available_result.txt\",\"r\") as f:\n",
    "    for line in f.readlines():\n",
    "        if(\"HITId:\" in line):\n",
    "            current_hit = line[7:-1]\n",
    "            hit_review[current_hit] = []\n",
    "        elif(\"Appr \"in line):\n",
    "            hit_review[current_hit].append(True)\n",
    "        elif(\"Reje \" in line or \"Midd \" in line):\n",
    "            hit_review[current_hit].append(False)\n",
    "with open(\"unavailable_result.txt\",\"r\") as f:\n",
    "    for line in f.readlines():\n",
    "        if(\"HITId:\" in line):\n",
    "            current_hit = line[7:-1]\n",
    "            hit_review[current_hit] = []\n",
    "        elif(\"Appr \"in line):\n",
    "            hit_review[current_hit].append(True)\n",
    "        elif(\"Reje \" in line or \"Midd \" in line):\n",
    "            hit_review[current_hit].append(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conbine approved answers & write into file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = [\"video_id\",\"question\",\"video_start_time\",\"video_end_time\",\"pos_tag\",\"standard_answer\",\"worker_answers\"]\n",
    "records = []\n",
    "for hit in hit_info.keys():\n",
    "    review_result = hit_review[hit]\n",
    "    info_answers = hit_info[hit]\n",
    "    for qind in range(QuestionNumber):\n",
    "        record = [info_answers[\"VideoIds\"][qind], info_answers[\"Questions\"][qind],info_answers[\"StartTimes\"][qind],\n",
    "                 info_answers[\"EndTimes\"][qind],info_answers[\"Postags\"][qind],info_answers[\"StdAnswers\"][qind]]\n",
    "        approved_answers = [info_answers[\"Answers\"][qind][idx] for idx in range(len(review_result)) if review_result[idx]]\n",
    "        not_empty_answers = sum([ aitem != [] for aitem in approved_answers])    # Amount of not empty answers\n",
    "        all_appr_answers = [ite2 for ite1 in approved_answers for ite2 in ite1]\n",
    "        if sum([\"unavailable video\" == ite for ite in all_appr_answers]) >= 2:   # unavailable video\n",
    "            record.append([])\n",
    "        else:\n",
    "            all_appr_freq = answer_frequency(all_appr_answers,not_empty_answers) # Frequency of each anser\n",
    "            if \"unavailable video\" in all_appr_freq:                             # False \"unvavilable video\" due to worker's reason\n",
    "                all_appr_freq.pop(\"unavailable video\")\n",
    "            record.append(all_appr_freq)\n",
    "        records.append(record)\n",
    "\n",
    "        df = pd.DataFrame(records,columns=titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"val1_50_mturk_appr_answers.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
